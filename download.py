#!/usr/bin/env python3
"""
å¹¶è¡Œä¸‹è½½ zip_links.txt ä¸­çš„æ‰€æœ‰ ZIP é“¾æ¥
"""
import os
import sys
import time
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
import requests
from tqdm import tqdm

LINKS_FILE = "zip_links.txt"
DOWNLOAD_DIR = Path("downloads")
WORKERS = min(32, (os.cpu_count() or 1) * 5)  # GitHub-hosted runner é€šå¸¸æ˜¯ 2 vCPU
CHUNK = 8192
TIMEOUT = 30
RETRY = 3

session = requests.Session()
session.headers.update({"User-Agent": "github-actions/zip-downloader"})

def read_links(path: str):
    if not Path(path).is_file():
        print(f"âŒ {path} ä¸å­˜åœ¨")
        sys.exit(1)
    with open(path, encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if line and not line.startswith("#"):
                yield line

def _fetch(url: str, dest: Path):
    """çœŸæ­£ä¸‹è½½çš„å‡½æ•°ï¼Œæ”¯æŒé‡è¯•"""
    for attempt in range(1, RETRY + 1):
        try:
            with session.get(url, stream=True, timeout=TIMEOUT) as r:
                r.raise_for_status()
                total = int(r.headers.get("content-length", 0))
                fname = Path(url).name or "download.zip"
                target = dest / fname
                target.parent.mkdir(parents=True, exist_ok=True)

                with open(target, "wb") as f, tqdm(
                    total=total,
                    unit="B",
                    unit_scale=True,
                    desc=f"{fname} ({attempt})",
                    leave=False,
                ) as bar:
                    for chunk in r.iter_content(chunk_size=CHUNK):
                        if chunk:
                            f.write(chunk)
                            bar.update(len(chunk))
                return url, True
        except Exception as e:
            if attempt == RETRY:
                return url, False
            time.sleep(2 ** attempt)

def main():
    DOWNLOAD_DIR.mkdir(exist_ok=True)
    links = list(read_links(LINKS_FILE))
    if not links:
        print("âš ï¸ æœªå‘ç°æœ‰æ•ˆé“¾æ¥")
        return

    print(f"ğŸ“¦ å¯åŠ¨ {WORKERS} çº¿ç¨‹å¹¶è¡Œä¸‹è½½ {len(links)} ä¸ªæ–‡ä»¶")
    ok = 0
    with ThreadPoolExecutor(max_workers=WORKERS) as pool:
        future_to_url = {pool.submit(_fetch, url, DOWNLOAD_DIR): url for url in links}
        for fut in tqdm(as_completed(future_to_url), total=len(links), desc="æ€»è¿›åº¦"):
            url, success = fut.result()
            if success:
                ok += 1
            else:
                print(f"âš ï¸ å¤šæ¬¡é‡è¯•åä»å¤±è´¥: {url}")
    print(f"âœ… å®Œæˆï¼ŒæˆåŠŸ {ok}/{len(links)}")

if __name__ == "__main__":
    main()